{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "def json_reader(fname, count=1000, stemming=True):\n",
    "    \"\"\"\n",
    "        Read multiple json files\n",
    "        Args:\n",
    "            fname: str: input file\n",
    "        Returns:\n",
    "            generator: iterator over documents \n",
    "    \"\"\"\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    p_stemmer = PorterStemmer()\n",
    "    \n",
    "    for line in open(fname, mode=\"r\"):\n",
    "        if (count <= 0):\n",
    "            break\n",
    "        count -= 1\n",
    "        \n",
    "        data = json.loads(line)\n",
    "        rating = int(data['stars'])\n",
    "        review = np.array(word_tokenize(data['text']))\n",
    "        if (not stemming):\n",
    "            yield {'rating': rating, 'review': review}\n",
    "            \n",
    "        stopped_tokens = filter(lambda token: token not in en_stop, review)\n",
    "        stemmed_tokens = map(lambda token: p_stemmer.stem(token), stopped_tokens)\n",
    "        review = np.array(list(stemmed_tokens))\n",
    "        yield {'rating': rating, 'review': review}        \n",
    "        \n",
    "        \n",
    "trainset = './dataset/NB/train.json'\n",
    "testset = './dataset/NB/test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25087\n",
      "Time Taken:  39.16308641433716\n"
     ]
    }
   ],
   "source": [
    "# Making of the dictionary\n",
    "tick = time.time()\n",
    "dictionary = {}\n",
    "for data in json_reader(trainset, 10000):\n",
    "    for word in data['review']:\n",
    "        dictionary[word] = 0\n",
    "        \n",
    "dictionary = { word : idx for idx, word in enumerate(dictionary)}\n",
    "print (len(dictionary))\n",
    "\n",
    "with open('dictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print (\"Time Taken: \", time.time() - tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dictionary\n",
    "with open('dictionary.pickle', 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1471 0.0849 0.1114 0.2155 0.4411] 10000\n",
      "[-1.91664265 -2.46628119 -2.19462795 -1.53479437 -0.81848367]\n"
     ]
    }
   ],
   "source": [
    "# Computing Phi's\n",
    "Phi = np.zeros(5)\n",
    "\n",
    "totalRatings = 0\n",
    "for data in json_reader(trainset, 10000):\n",
    "    totalRatings += 1\n",
    "    Phi[data['rating'] - 1] += 1\n",
    "    \n",
    "Phi /= totalRatings\n",
    "print (Phi, totalRatings)\n",
    "\n",
    "Phi = np.log(Phi)\n",
    "print (Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25087\n",
      "[[1.40e+01 1.40e+01 3.70e+01 1.66e+02 4.23e+02]\n",
      " [1.00e+01 3.00e+00 4.00e+00 4.00e+00 4.00e+00]\n",
      " [5.95e+02 3.75e+02 6.13e+02 1.12e+03 1.28e+03]\n",
      " ...\n",
      " [1.00e+00 1.00e+00 2.00e+00 1.00e+00 1.00e+00]\n",
      " [1.00e+00 1.00e+00 2.00e+00 1.00e+00 1.00e+00]\n",
      " [1.00e+00 1.00e+00 2.00e+00 1.00e+00 1.00e+00]]\n",
      "[[166181. 108560. 131491. 204636. 309492.]\n",
      " [166181. 108560. 131491. 204636. 309492.]\n",
      " [166181. 108560. 131491. 204636. 309492.]\n",
      " ...\n",
      " [166181. 108560. 131491. 204636. 309492.]\n",
      " [166181. 108560. 131491. 204636. 309492.]\n",
      " [166181. 108560. 131491. 204636. 309492.]]\n",
      "[[ -9.38  -8.96  -8.18  -7.12  -6.6 ]\n",
      " [ -9.72 -10.5  -10.4  -10.84 -11.26]\n",
      " [ -5.63  -5.67  -5.37  -5.21  -5.49]\n",
      " ...\n",
      " [-12.02 -11.6  -11.09 -12.23 -12.64]\n",
      " [-12.02 -11.6  -11.09 -12.23 -12.64]\n",
      " [-12.02 -11.6  -11.09 -12.23 -12.64]]\n",
      "Time Taken:  45.88801407814026\n"
     ]
    }
   ],
   "source": [
    "# Computing ThetaWK's\n",
    "V = len(dictionary)\n",
    "print (V)\n",
    "\n",
    "tick = time.time()\n",
    "\n",
    "ThetaNum = np.zeros((V, 5)) + 1\n",
    "ThetaDeno = np.zeros((V, 5)) + V \n",
    "\n",
    "def computeFreq (doc, rating):\n",
    "    k = rating - 1\n",
    "    ThetaDeno[:, k] += len(doc)\n",
    "    \n",
    "    for word in doc:\n",
    "        w = dictionary[word]\n",
    "        ThetaNum[w][k] += 1\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "for data in json_reader(trainset, 10000):\n",
    "    computeFreq (data['review'], data['rating'])\n",
    "    \n",
    "Theta = np.log(ThetaNum / ThetaDeno)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "print (ThetaNum)\n",
    "print (ThetaDeno)\n",
    "print (Theta)\n",
    "\n",
    "print (\"Time Taken: \", time.time() - tick)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "def predictClass (doc):\n",
    "    probs = np.zeros(5)\n",
    "    for k in range(0, 5):\n",
    "        probs[k] += Phi[k];\n",
    "        for word in doc:\n",
    "            if word not in dictionary:\n",
    "                continue\n",
    "            w = dictionary[word]\n",
    "            probs[k] += Theta[w][k]\n",
    "    return np.argmax(probs) + 1\n",
    "\n",
    "def randomPredictions (doc):\n",
    "    return np.random.randint(1, 6)\n",
    "    \n",
    "    \n",
    "def majorityPrediction (doc):\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Accuracy: 59.90%\n",
      "Time Taken:  42.52086591720581\n"
     ]
    }
   ],
   "source": [
    "# Actual Predictions\n",
    "tick = time.time()\n",
    "\n",
    "correctPredictions = 0\n",
    "totalPredictions = 0\n",
    "for data in json_reader(testset, 10000):\n",
    "    prediction = predictClass (data['review'])\n",
    "    totalPredictions += 1\n",
    "    if (prediction == data['rating']):\n",
    "        correctPredictions += 1\n",
    "    \n",
    "print (totalPredictions)\n",
    "print (\"Accuracy: %.2f%%\" % (correctPredictions * 100 / totalPredictions))\n",
    "print (\"Time Taken: \", time.time() - tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Accuracy: 19.39%\n",
      "Time Taken:  34.2642822265625\n"
     ]
    }
   ],
   "source": [
    "# Random Predictions\n",
    "tick = time.time()\n",
    "\n",
    "correctPredictions = 0\n",
    "totalPredictions = 0\n",
    "for data in json_reader(testset, 10000):\n",
    "    prediction = randomPredictions (data['review'])\n",
    "    totalPredictions += 1\n",
    "    if (prediction == data['rating']):\n",
    "        correctPredictions += 1\n",
    "    \n",
    "print (totalPredictions)\n",
    "print (\"Accuracy: %.2f%%\" % (correctPredictions * 100 / totalPredictions))\n",
    "print (\"Time Taken: \", time.time() - tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Accuracy: 44.14%\n",
      "Time Taken:  37.610371351242065\n"
     ]
    }
   ],
   "source": [
    "# Majority Predictions\n",
    "tick = time.time()\n",
    "\n",
    "correctPredictions = 0\n",
    "totalPredictions = 0\n",
    "for data in json_reader(testset, 10000):\n",
    "    prediction = majorityPrediction (data['review'])\n",
    "    totalPredictions += 1\n",
    "    if (prediction == data['rating']):\n",
    "        correctPredictions += 1\n",
    "    \n",
    "print (totalPredictions)\n",
    "print (\"Accuracy: %.2f%%\" % (correctPredictions * 100 / totalPredictions))\n",
    "print (\"Time Taken: \", time.time() - tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  44.589205741882324\n",
      "Confusion matrix, without normalization\n",
      "[[1183   67   57  120  101]\n",
      " [ 282   75  133  252  101]\n",
      " [ 140   22  150  573  191]\n",
      " [  89    7   59 1097  887]\n",
      " [ 189    4   16  720 3485]]\n",
      "Normalized confusion matrix\n",
      "[[0.77 0.04 0.04 0.08 0.07]\n",
      " [0.33 0.09 0.16 0.3  0.12]\n",
      " [0.13 0.02 0.14 0.53 0.18]\n",
      " [0.04 0.   0.03 0.51 0.41]\n",
      " [0.04 0.   0.   0.16 0.79]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class_names = np.array(['1', '2', '3', '4', '5'])\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "# Load the training data and predictions\n",
    "tick = time.time()\n",
    "ratings = []\n",
    "predictions = []\n",
    "for data in json_reader(testset, 10000):\n",
    "    prediction = predictClass (data['review'])\n",
    "    ratings.append(data['rating'] - 1)\n",
    "    predictions.append(prediction - 1)\n",
    "ratings = np.array(ratings)\n",
    "predictions = np.array(predictions)\n",
    "print (\"Time Taken: \", time.time() - tick)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(ratings, predictions, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(ratings, predictions, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
